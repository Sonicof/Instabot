# verify_setup.py
"""
Verification script to ensure all components are working correctly
Run this after setup to verify your RAG system is ready
"""

import sys
import subprocess
import requests
import time

def check_python_packages():
    """Check if all required Python packages are installed"""
    print("üêç Checking Python packages...")
    
    required_packages = [
        'chromadb', 'langchain', 'langchain_community', 
        'langchain_ollama', 'sentence_transformers', 
        'ollama', 'pytest', 'dotenv'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
            print(f"  ‚úÖ {package}")
        except ImportError:
            print(f"  ‚ùå {package} - MISSING")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\n‚ùå Missing packages: {', '.join(missing_packages)}")
        print("Install with: pip install " + " ".join(missing_packages))
        return False
    
    print("‚úÖ All Python packages installed!")
    return True

def check_ollama_service():
    """Check if Ollama service is running"""
    print("\nü§ñ Checking Ollama service...")
    
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("  ‚úÖ Ollama service is running")
            return True
        else:
            print(f"  ‚ùå Ollama service returned status: {response.status_code}")
            return False
    except requests.exceptions.RequestException:
        print("  ‚ùå Ollama service is not running")
        print("  üí° Start with: ollama serve")
        return False

def check_ollama_models():
    """Check if required Ollama models are installed"""
    print("\nüì¶ Checking Ollama models...")
    
    required_models = ["llama3.2:3b", "nomic-embed-text"]
    
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code != 200:
            print("  ‚ùå Cannot check models - Ollama service issue")
            return False
        
        installed_models = [model["name"] for model in response.json()["models"]]
        
        missing_models = []
        for model in required_models:
            if any(model in installed for installed in installed_models):
                print(f"  ‚úÖ {model}")
            else:
                print(f"  ‚ùå {model} - MISSING")
                missing_models.append(model)
        
        if missing_models:
            print(f"\n‚ùå Missing models: {', '.join(missing_models)}")
            print("Install with:")
            for model in missing_models:
                print(f"  ollama pull {model}")
            return False
        
        print("‚úÖ All required models installed!")
        return True
        
    except Exception as e:
        print(f"  ‚ùå Error checking models: {e}")
        return False

def test_ollama_embedding():
    """Test Ollama embedding functionality"""
    print("\nüîç Testing Ollama embeddings...")
    
    try:
        from langchain_ollama import OllamaEmbeddings
        
        embeddings = OllamaEmbeddings(
            model="nomic-embed-text",
            base_url="http://localhost:11434"
        )
        
        # Test embedding
        test_text = "This is a test sentence for embedding."
        result = embeddings.embed_query(test_text)
        
        if isinstance(result, list) and len(result) > 0:
            print(f"  ‚úÖ Embedding generated successfully (dimension: {len(result)})")
            return True
        else:
            print("  ‚ùå Invalid embedding result")
            return False
            
    except Exception as e:
        print(f"  ‚ùå Embedding test failed: {e}")
        return False

def test_ollama_llm():
    """Test Ollama LLM functionality"""
    print("\nüí¨ Testing Ollama LLM...")
    
    try:
        from langchain_ollama import OllamaLLM
        
        llm = OllamaLLM(
            model="llama3.2:3b",
            base_url="http://localhost:11434",
            temperature=0.1
        )
        
        # Test generation
        test_prompt = "What is 2+2? Answer with just the number."
        result = llm.invoke(test_prompt)
        
        if result and isinstance(result, str):
            print(f"  ‚úÖ LLM responded: '{result.strip()}'")
            return True
        else:
            print("  ‚ùå Invalid LLM response")
            return False
            
    except Exception as e:
        print(f"  ‚ùå LLM test failed: {e}")
        return False

def test_rag_system():
    """Test basic RAG system functionality"""
    print("\nüéØ Testing RAG system...")
    
    try:
        from rag_system import RAGSystem
        
        # Initialize RAG system
        rag = RAGSystem()
        
        # Add test text
        test_text = """
        Python is a high-level programming language. 
        It was created by Guido van Rossum and first released in 1991.
        Python is known for its simple syntax and readability.
        """
        
        rag.add_text(test_text, "test_doc.txt")
        
        # Test query
        result = rag.query("Who created Python?")
        
        if result and result["answer"]:
            print(f"  ‚úÖ RAG system working! Answer: {result['answer'][:100]}...")
            return True
        else:
            print("  ‚ùå RAG system test failed")
            return False
            
    except Exception as e:
        print(f"  ‚ùå RAG system test failed: {e}")
        return False

def print_system_info():
    """Print system information"""
    print("\nüìä System Information:")
    print(f"  Python version: {sys.version}")
    
    try:
        import torch
        print(f"  PyTorch available: {torch.__version__}")
    except ImportError:
        print("  PyTorch: Not installed")
    
    # Check available memory (approximate)
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"  Available RAM: {memory.available // (1024**3)} GB / {memory.total // (1024**3)} GB")
    except ImportError:
        print("  Memory info: psutil not available")

def main():
    """Run all verification checks"""
    print("üîß RAG System Setup Verification")
    print("=" * 50)
    
    # Print system info
    print_system_info()
    
    # Run checks
    checks = [
        check_python_packages(),
        check_ollama_   service(),
        check_ollama_models(),
        test_ollama_embedding(),
        test_ollama_llm(),
        test_rag_system()
    ]
    
    print("\n" + "=" * 50)
    print("üìã VERIFICATION SUMMARY")
    print("=" * 50)
    
    passed = sum(checks)
    total = len(checks)
    
    if passed == total:
        print("üéâ ALL CHECKS PASSED!")
        print("‚úÖ Your RAG system is ready to use!")
        print("\nüöÄ Next steps:")
        print("  1. Run: python quick_start.py")
        print("  2. Or run: python text_loader.py")
        print("  3. Start asking questions about your documents!")
    else:
        print(f"‚ö†Ô∏è  {passed}/{total} checks passed")
        print("‚ùå Please fix the issues above before proceeding")
        print("\nüí° Common solutions:")
        print("  - Install missing packages: pip install [package_name]")
        print("  - Start Ollama: ollama serve")
        print("  - Pull models: ollama pull llama3.2:3b")
        print("  - Pull models: ollama pull nomic-embed-text")

if __name__ == "__main__":
    main()